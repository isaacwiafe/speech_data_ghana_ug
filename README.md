# UGSpeechData - Audio speech dataset of 5 Ghanaian languages - Akan, Ewe, Dagbani, Dagaare, and Ikposo
The dataset comprises of 5000 hours speech corpus in Akan, Ewe, Dagbani, Daagare, and Ikposo. Each language includes 1000 hours of audio speech from indigenous speakers of the language and 100 hours of transcription. 


# Link(s) to Data Assets 
<!--- + [Transcribed Audio Samples](https://ugedugh-my.sharepoint.com/:f:/g/personal/speechdata_ug_edu_gh/Ejb6UHk-E7VOlvccvCWel44BhcSvTnEDh3FBGNtlZBy8kA?e=bLaHaF) --->

<!---* [Images](https://www.dropbox.com/scl/fo/2q6lvqtn4qm0w6t0iyxm0/h?rlkey=uz9l13khtdhdouvcca7nba5qi&dl=0](https://www.dropbox.com/scl/fo/2q6lvqtn4qm0w6t0iyxm0/h?rlkey=uz9l13khtdhdouvcca7nba5qi&dl=0)) --->

*   [Local Audios + AUDIO ID.csv](https://www.dropbox.com/scl/fo/e9bha9glyvk2mu5fo7f3h/h?rlkey=kzm1mnx8bj6qgicpaxojz1npa&dl=0)

  <!---  [Transcriptions](https://www.dropbox.com/scl/fo/qouaom0adtkaux7u7c5gr/h?rlkey=8vy27eb2u9dhrsrh7bzbtq6zc&dl=0) --->


<h2>AUDIO_ID.csv Description</h2>

<table>
  <thead>
    <tr>
      <th>Column</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>IMAGE_URL</code></td>
      <td>Provides the relative path to the images in the folder</td>
    </tr>
    <tr>
      <td><code>IMAGE_SRC_URL</code></td>
      <td>Provides the source path to the actual image online</td>
    </tr>
    <tr>
      <td><code>AUDIO_URL</code></td>
      <td>Provides the relative path to the local audio language in the Local Audio folder</td>
    </tr>
    <tr>
      <td><code>ORG_NAME</code></td>
      <td>Identifies the institution coordinating the audio collection</td>
    </tr>
    <tr>
      <td><code>PROJECT_NAME</code></td>
      <td>Provides the name of the project</td>
    </tr>
    <tr>
      <td><code>SPEAKER_ID</code></td>
      <td>Provides the ID number of the individual describing the image</td>
    </tr>
    <tr>
      <td><code>LOCALE</code></td>
      <td>Provides the local language IETF BCP 47 language tag of the audio file</td>
    </tr>
    <tr>
      <td><code>GENDER</code></td>
      <td>Provides the individual providing the audio description gender</td>
    </tr>
    <tr>
      <td><code>AGE</code></td>
      <td>Provides the individual providing the audio description age</td>
    </tr>
    <tr>
      <td><code>DEVICE</code></td>
      <td>Identifies the device from which the audio recording was done</td>
    </tr>
    <tr>
      <td><code>ENVIRONMENT</code></td>
      <td>Identifies the space within which the audio was recorded</td>
    </tr>
    <tr>
      <td><code>YEAR</code></td>
      <td>The year in which the audio was recorded</td>
    </tr>
  </tbody>
</table>

<h3>Note: Local IDs</h3>

<table>
  <thead>
    <tr>
      <th>Locale ID</th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ak_gh</code></td>
      <td>Akan</td>
    </tr>
    <tr>
      <td><code>dga_gh</code></td>
      <td>Dagbani</td>
    </tr>
    <tr>
      <td><code>dag_gh</code></td>
      <td>Dagaare</td>
    </tr>
    <tr>
      <td><code>ee_gh</code></td>
      <td>Ewe</td>
    </tr>
    <tr>
      <td><code>kpo_gh</code></td>
      <td>Ikposo</td>
    </tr>
  </tbody>
</table>



# CITATION
Wiafe, I., Abdulai, J., Ekpezu, A. O., Dodzie, R., Atsakpo, E. D., Nutrokpor, C., Winful, F. B. P., & Solaga, K. K. (2023). UGSPEECHDATA (Version 1.0.0) [Data set]. https://github.com/isaacwiafe/speech_data_ug
